# Phase 01: DELETE

**Before You Build, Strip Away What Doesn't Matter**

---

## The Principle

Deletion is the first operation in the **Delete / Distort / Generalize** framework. Before you can build anything meaningful, you must strip away what is no longer true, what was never true, and what you have been afraid to examine.

In the novel *Just Ask*, David Lin spends eighteen months building consulting frameworks, a SaaS product, and a personal brand -- all without asking a single person what they actually need. He is applying "lemon juice" -- executing confidently within a framework that has no relationship to the actual problem.

Phase 01 walks you through the same reckoning. Not to tear you down, but to clear the ground. You cannot plant in cluttered soil.

---

## Lessons in This Phase

| # | Lesson | Key Question | Deliverable |
|---|--------|-------------|-------------|
| 1 | [The Close Button](lesson-close-button.md) | What expertise have I been clinging to that the world has already moved past? | List of expired assumptions |
| 2 | [Lemon Juice](lesson-lemon-juice.md) | Where am I confidently doing the wrong thing? | Your "lemon juice" identified |
| 3 | [Why Before How](lesson-why-before-how.md) | What problem am I actually solving? | One-sentence problem statement |

---

## What You Will Delete

By the end of this phase, you will have identified:

- **Expired assumptions** -- skills, credentials, or beliefs about your value that no longer match reality
- **Invisible biases** -- strategies that feel productive but produce nothing (your lemon juice)
- **The wrong question** -- the gap between the problem you have been solving and the problem that actually matters

These are not failures. They are filters. Your brain runs them automatically to protect you from uncomfortable truths. The Writitation practice makes them visible.

---

## How Deletion Works

In human cognition, deletion is how we manage the infinite complexity of experience. We filter out most of what we perceive so we can function. The problem is that we also delete signals that matter -- the evidence that a career is ending, the feedback that a product has no market, the quiet voice that says *this is not what I want*.

In large language models, deletion happens through the attention mechanism. The model assigns low weights to tokens it deems irrelevant, effectively deleting them from consideration. This is how a transformer focuses -- by ignoring what does not matter.

Both systems face the same risk: deleting the wrong thing.

This phase trains you to **delete consciously** -- to choose what to strip away instead of letting your unconscious mind do it for you.

---

*Begin with [The Close Button](lesson-close-button.md).*
